{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4740_Lab_Week_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnmP1B/vzOc2MtUuULsjBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvogiatzis/CS4740/blob/main/CS4740_Lab_Week_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDVelHbR_KqJ"
      },
      "source": [
        "# CS4740 Labs\n",
        "## Week 3 - Networks in Pytorch\n",
        "\n",
        "In this lab we will be continuing with our exploration of Deep Learning and Pytorch by carrying out some more classification experiments, this time in image data. \n",
        "\n",
        "The MNIST dataset, created almost 30 years ago, is one of the most commonly used machine learning datasets. It consists of 60,000 tiny images (28x28) of handwritten digits that must be correctly classified into one of 10 classes. Widely considered as the \"hello world\" equivalent for ML researchers, it is the go-to dataset for any new algorithm that is proposed for image classification and ML in general. As the old saying goes, \"If it doesn't work on MNIST, it won't work at all\". \n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Steven_Young11/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)\n",
        "\n",
        "Just to be different, and a little more ambitious, we will be using a more recent and significantly more challenging dataset, known as KMNIST, that consists of 28x28 images of handwritten Japanese kuzushiji (18th c. cursive calligraphy) characters (10 classes out of the possible 49).\n",
        "\n",
        "![alt text](http://codh.rois.ac.jp/img/kmnist.png)\n",
        "\n",
        "The image above shows examples from the ten classes in the dataset with the first collumn representing the modern Hiragana printed version. See this [paper](https://arxiv.org/pdf/1812.01718.pdf) for more technical details. More about the fascinating history of kuzushiji [here](http://naruhodo.weebly.com/blog/introduction-to-kuzushiji)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8QEflgjv9vG"
      },
      "source": [
        "# Section 1. Loading up the dataset\n",
        "\n",
        "Fortunately for us, Pytorch already comes with utility classes for downloading and using a whole host of interesting ML datasets under the `torchvision.datasets` module. Let's begin by downloading both the training and test subsets of the KMNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av39uznD2nIN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "train_dataset = torchvision.datasets.KMNIST('.', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.KMNIST('.', train=False, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sqw6-mZjE3S"
      },
      "source": [
        "The `KMNIST` helper function can be conveniently supplied with a transform object that can be used to perform all kinds of operation on a datapoint prior to its use. We can apply dataset normalization, data augmentation , image cropping, histogram equalization etc. Here we use the `ToTensor` to transform PIL images into pytorch tensors. \n",
        "\n",
        "Each datapoint will consist of a pair of image (converted into a tensor) and a number from 0 to 9 corresponding to class. Let's display a sample image with its target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg3wxSDkj3Qk"
      },
      "source": [
        "img, target = train_dataset[999]\n",
        "plt.imshow(img.squeeze())\n",
        "print(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpRd9DkKnyd3"
      },
      "source": [
        "Last week we applied Logistic Regression to some very simple data and we learned how to use direcly some torch layers such as `torch.nn.Linear`. This time we will see how to package everything into a single network object. This provides a number of benefits such as, automatically extracting the list of all model parameters (for optimization) or moving the whole network on to the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Gug0VeFk_8"
      },
      "source": [
        "## Section 2. Creating a network\n",
        "\n",
        "To create your own neural network architecture you must subclass the torch.nn.Module class. This involves writting a constructor, where all the member variables are defined and initialized, and overload the .forward() method which describes how the network input is transformed to the output. The beauty of Pytorch is that it then handles the .backward() method automatically (details in lecture). Let's write a simple logistic regression network, to warm us up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQy7BQHNnxu4"
      },
      "source": [
        "class LogisticNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticNet, self).__init__()\n",
        "        self.fc = nn.Linear(784, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,784)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x,dim=1)\n",
        "        return x\n",
        "\n",
        "lognet = LogisticNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp3KSGHgsC_U"
      },
      "source": [
        "Note that the line \n",
        "```\n",
        "x = x.view(-1,784)\n",
        "```\n",
        "has the effect of **flattening** the image into a vector of 28x28=784 elements.\n",
        "\n",
        "And that's it! In 8 lines of code (most of which is boilerplate anyway) you've programmed your first neural network. Its weights have also been conveniently initialized so let's give it a spin on an actual datapoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdZg9EJysCDv"
      },
      "source": [
        "img, target = train_dataset[999]\n",
        "\n",
        "print(torch.exp(lognet(img)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OEvsf8yvJC5"
      },
      "source": [
        "These are the probabilities that our network assigns to each of the ten classes for this datapoint. Note that the network outputs log-probabilities because of better numerics so to get to an actual distribution we must exponentiate. Of course we haven't done any training yet so the numbers are random. So let's write some training code. This will take the, by now familiar pattern of forward step, loss function calculation, backward step. The only difference is that we will be using mini-batches. See lecture for more details but mini-batch training means we will be updating the network weights by computing the loss function (and its gradient) on small subsets of the dataset, usually around 64 datapoints at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x0MqOO7F20F"
      },
      "source": [
        "## Section 3. Training and testing\n",
        "\n",
        "It is very good to get into the habit of using the torch.utils.data.DataLoader to help with randomly shuffling the data, splitting it into mini-batches as well as optimizing the concurrent data access with number crunching code. The call to the dataloader constructor looks as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47M1jLRTyoYh"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=1000, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA3J3b0mytDT"
      },
      "source": [
        "The dataloader objects are accessed through iterators and they iterate through every minibatch. To get the very first minibatch of images and targets we would do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5OdRmYwzgxa"
      },
      "source": [
        "x, t = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FVlQO2i0ZtT"
      },
      "source": [
        "print(x.shape)\n",
        "print(t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRQwuMVr0O_c"
      },
      "source": [
        "So the data minibatch consists of 64 images. Let's define a standard negative log likelihood loss function and evaluate it on this data/target mini-batch. Now most pytorch layers (Linear, Conv, MaxPool etc) are clever enough to be applied on a minibatch, i.e. on all tensor dimensions except the minibatch dimension which is the first one. Loss functions on the other hand will be reduced (by averaging or summing) across the mini-batch to a single scalar. We will then call `.backward()` on that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNA_Zy5sz1dY"
      },
      "source": [
        "loss = nn.NLLLoss()\n",
        "print(loss(lognet(x),t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8xoRxlK1o5q"
      },
      "source": [
        "Let's also create an SGD optimizer object as in the previous lab, with a learning rate of 0.01 and momentum parameter=0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BriYEjnn1zim"
      },
      "source": [
        "optim_SGD = optim.SGD(lognet.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vui403tZ2D8H"
      },
      "source": [
        "We can now write our training routine. You will find a variant of this code snippet in essentially all pytorch code you ever come across. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehxcwjTT2DJh"
      },
      "source": [
        "def train(net,dataloader, optimizer,loss_fun):\n",
        "  net.train()\n",
        "  for x, t in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    L = loss_fun(net(x), t)\n",
        "    L.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52YtZ-iQ2kMC"
      },
      "source": [
        "But before running this, we need to make sure we evaluate the performance of our model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZdNEsrJ8h8Z"
      },
      "source": [
        "def test(net,dataloader,loss_fun):\n",
        "  net.eval()\n",
        "  total_L = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for x, t in dataloader:\n",
        "      out = net(x)\n",
        "      total_L += loss_fun(out, t)\n",
        "      _,pred = out.max(dim=1)     # this counts how many we got right\n",
        "      correct += (pred==t).sum() \n",
        "  total_L /= len(dataloader.dataset)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    total_L, correct, len(dataloader.dataset),\n",
        "    100. * correct / len(dataloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "910GxAQ-6fQb"
      },
      "source": [
        "The test code contains essentially only the forward part of the computation. We will be applying it onto the test dataset and with a loss function that does not average, so we can sum it across the whole dataset. The only other difference is that we can use a much bigger mini-batch size because we don't have to worry about the memory-intensive backward step.\n",
        "\n",
        "If we test the performance of the network now, before any training, it should be roughly on 10% (i.e. random correct prediction of 10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H3RRADu_L_x"
      },
      "source": [
        "print(\"Testing before any training ...\")\n",
        "test(lognet, test_loader,  nn.NLLLoss(reduction='sum'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFpecisa-4hX"
      },
      "source": [
        "\n",
        "Let us now do a few train-test iterations, or **epochs** as they are known in the trade:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rq8v7K67GxR"
      },
      "source": [
        "for e in range(10):\n",
        "  print(f\"Epoch: {e+1}/10. Training ...\")\n",
        "  train(lognet, train_loader, optim_SGD, nn.NLLLoss())\n",
        "  print(\"Testing ...\")\n",
        "  test(lognet, test_loader,  nn.NLLLoss(reduction='sum'))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH4c5G2Y_t2X"
      },
      "source": [
        "What performance did you manage to get? You should find that it usually tails off at around 70%. That is definitely better than random but not terribly good. Let us try a different network that includes one hidden layer with a ReLU activation (rectified linear unit, whose response is given by y=max(0,x) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX7dOGFlAM0n"
      },
      "source": [
        "class MLPNet(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(MLPNet, self).__init__()        \n",
        "        self.fc1 = nn.Linear(784, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x,dim=1)\n",
        "        return x\n",
        "\n",
        "mlpnet = MLPNet(256)\n",
        "\n",
        "optim_SGD = optim.SGD(mlpnet.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuFgH7B6E7CF"
      },
      "source": [
        "Let's train and test as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S69oQoiAqP0"
      },
      "source": [
        "print(\"Testing before any training ...\")\n",
        "test(mlpnet, test_loader,  nn.NLLLoss(reduction='sum'))\n",
        "\n",
        "for e in range(20):\n",
        "  print(f\"Epoch: {e+1}/20. Training ...\")\n",
        "  train(mlpnet, train_loader, optim_SGD, nn.NLLLoss())\n",
        "  print(\"Testing ...\")\n",
        "  test(mlpnet, test_loader,  nn.NLLLoss(reduction='sum'))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnPEdFLdTRRi"
      },
      "source": [
        "Your performance should now be edging towards 90%. Nice! \n",
        "\n",
        "But is it possible to shed some more light as to how the network is performing its computation? Actually in shallow networks such as our MLP, we can sometimes visualize what is going on at least in the first layer, by rendering the weights as images. These weights are essentially patterns that the network is trying to match in the input image. We can access the weights of the first layer `fc1` and use the `.view` method to reshape them into a sequence of 28x28 images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJRSoaQmUApy"
      },
      "source": [
        "filters = mlpnet.fc1.weight.view(-1, 28, 28).detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS0zMP6rUSPj"
      },
      "source": [
        "We can then use the `make_grid` command from the `torchvision.utils` module to create a MxN grid of images. Just render them with the `imshow` command in `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ttb6Y_UOzgN"
      },
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "grid=make_grid(filters[0:50,None,:,:], nrow=10,normalize=True)\n",
        "plt.imshow(grid.permute(1,2,0),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABqQUcD1GSDC"
      },
      "source": [
        "We can definitely observe some faint patterns corresponding to some of those hiragana script characters. These patterns are the basic level **decisions** that the network is making in the first layer. The output of those decisions is then fed to subsequent layers for more high-level processing until at the end the network is able to infer the class of the input image.\n",
        "\n",
        "## Section 4. Challenges\n",
        "\n",
        "\n",
        "1.   By modifying the mlpnet, can you try a network with two or more hidden layers?\n",
        "2.   Can modify the testing code so that it prints out more detailed error analysis? E.g. accuracy per class, topK  etc) \n",
        "3.   In a similar vein, can you compute a confusion matrix? I.e. can you count the number of datapoints that belonged to class a, and were classified as class b, for a,b in 0,1,2,...,10 ?\n",
        "4. Can you try other datasets in pytorch? You can directly drop in MNIST (run `torchvision.datasets.MNIST`) which has same resolution images but for extra challenge, can you apply your algorithm on CIFAR-10? (run `torchvision.datasets.CIFAR10`) That dataset contains 60,000 color images of 32x32 resolution (so the shape of each image is 3x32x32)\n",
        "\n"
      ]
    }
  ]
}