{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4740_Lab_Week_05b.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYjLapFatTh+5sHW1x12EU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvogiatzis/CS4740/blob/main/CS4740_Lab_Week_05b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLVrEeFtaICL"
      },
      "source": [
        "#Exploring the capabilities of Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4MZ5yQgaUSs"
      },
      "source": [
        "In this lab we will carry out a few experiments with Recurrent Neural Networks in order to understand the way these models operate and also to see some interesting applications. RNNs are Deep Learning models that are particularly suitable for sequential data such as time series, text, speech, audio signals etc.\n",
        "\n",
        "We can think of an RNN as a *machine* that is fed a sequence of data-points. After each data-point is entered, the machine performs some calculations based on the information received, and it  modifies its inner state appropriately. It then produces some output before moving to the next data-point in the sequence. \n",
        "\n",
        "We can use RNNs in a multitude of ways:\n",
        "\n",
        "* We can use the last RNN output after a sequence has been read, to make some inference about the type of sequence. E.g. classifying a bit of text into one of a number of categories.\n",
        "* We can use an RNN to encode an input sequence, and pass a code to a second RNN that decodes that into an output sequence. This can form the basis of a sequence-to-sequence mapping, e.g. translation of english to french text\n",
        "* We can use an RNN as a next-step predictor. E.g. predicting the next day's stock market price from a s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsD64X1cnGv5"
      },
      "source": [
        "import re\n",
        "import csv\n",
        "from textblob import Word\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from more_itertools import sliced\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from random import randint\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siTTVNNMnIzy"
      },
      "source": [
        "class CounterNet(nn.Module):\n",
        "    def __init__(self, embed_size=10, hidden_dim=16):\n",
        "        super(CounterNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(2, embed_size)\n",
        "        self.lstm = nn.GRU(input_size=embed_size,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, batch_size=1):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x).squeeze(dim=2)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugpeiR3hpdNT",
        "outputId": "86f057b4-7d96-4438-885d-a9b7d4ec61cc"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size=100\n",
        "num_of_epochs = 5000\n",
        "net = CounterNet().to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss = nn.MSELoss()\n",
        "for e in range(num_of_epochs):\n",
        "    # seq_length = randint(10,50)\n",
        "    x = torch.randint(2, (batch_size,50), device=device)\n",
        "    t = x.cumsum(dim=1,dtype=torch.float32)\n",
        "    y = net(x)\n",
        "    L = loss(y,t)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"\\rEpoch: {e}/{num_of_epochs} \\tL={L}\", end=\"\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4999/5000 \tL=0.12704047560691833"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBkYRRwGMPF6"
      },
      "source": [
        "itoc=list('0123456789+=. ')\n",
        "ctoi = {c:i for i,c in enumerate(itoc)}\n",
        "\n",
        "def create_strings(a,b):\n",
        "    c=a+b\n",
        "    a_s=str(a)\n",
        "    b_s=str(b)\n",
        "    c_s=str(c)\n",
        "    input = f'{a_s}+{b_s}={c_s}'\n",
        "    output = f'{c_s}.'\n",
        "    input = f'{a_s}+{b_s}'\n",
        "    output=' ' * len(input)\n",
        "    input += f'={c_s}'\n",
        "    output+= f'{c_s}.'\n",
        "\n",
        "    \n",
        "    return input, output\n",
        "\n",
        "def create_addition_samples(num_samples,ndigits):\n",
        "    x,t,pairs=[],[],[]\n",
        "    for n in range(num_samples):\n",
        "        a = randint(0,10**ndigits-1)\n",
        "        b = randint(0,10**ndigits-1)\n",
        "        input, output = create_strings(a,b)\n",
        "        input = input.ljust(3*ndigits+3, ' ')\n",
        "        output = output.ljust(3*ndigits+3, ' ')\n",
        "        x.append([ctoi[c] for c in input])\n",
        "        t.append([ctoi[c] for c in output])\n",
        "        pairs.append((a,b))\n",
        "    return x,t,pairs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBxS4ztrzJUX"
      },
      "source": [
        "class AdderNet(nn.Module):\n",
        "    def __init__(self, charset=13, embed_size=15, hidden_dim=1024):\n",
        "        super(AdderNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(charset, embed_size)\n",
        "        self.rnn = nn.GRU(input_size=embed_size,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, charset)\n",
        "        self.h = None\n",
        "\n",
        "    def forward(self, x, batch_size=1, keep_memory=False):\n",
        "        x = self.embedding(x)\n",
        "        if keep_memory:\n",
        "            x, self.h = self.rnn(x,self.h)\n",
        "        else:\n",
        "            x, self.h = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def eval_adder(net, input_str):\n",
        "    itoc=list('0123456789+=. ')\n",
        "    ctoi = {c:i for i,c in enumerate(itoc)}\n",
        "    input = torch.tensor([[ctoi[c] for c in input_str]], device = device)\n",
        "    x = net(input).argmax(dim=2)\n",
        "    x = x[0,-1].view(1,-1)\n",
        "    output = [x.item()]\n",
        "    total_len=0\n",
        "    while x.item() != ctoi['.'] and total_len<10:\n",
        "        x = net(x, keep_memory=True).argmax(dim=2)\n",
        "        output.append(x.item())\n",
        "        total_len+=1\n",
        "    return \"\".join(itoc[i] for i in output)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "749bTBqANrty",
        "outputId": "ee2287a4-aa6b-40ec-b714-1ce4ad9d43e6"
      },
      "source": [
        "training_data=set()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size=100\n",
        "num_of_epochs = 5000\n",
        "ndigits=3\n",
        "net = AdderNet(charset = len(itoc)).to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "for e in range(num_of_epochs):\n",
        "    x,t,pairs = create_addition_samples(batch_size,ndigits=ndigits)\n",
        "    training_data =training_data.union(set(pairs))\n",
        "    x = torch.tensor(x,device=device)\n",
        "    t = torch.tensor(t,device=device)\n",
        "    y = net(x)\n",
        "    L = loss(y.view(-1,y.shape[-1]),t.view(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"\\rEpoch: {e}/{num_of_epochs} \\tL={L}\", end=\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4999/5000 \tL=0.018413158133625984"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJaY7vaEm3on"
      },
      "source": [
        "all_pairs = set((a,b) for a in range(1000) for b in range(1000))\n",
        "unseen_data=list(all_pairs.difference(training_data))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wimaOiEo1tg",
        "outputId": "a2b1d63b-1a43-4e00-a192-bfea39df6af4"
      },
      "source": [
        "errors=0\n",
        "for i,(a,b) in enumerate(unseen_data):\n",
        "    input, output = create_strings(a,b)\n",
        "    # net_output = eval(eval_adder(net, input[:input.find('=')+1]))\n",
        "    try:\n",
        "        target = eval(input[:input.find('=')])\n",
        "        output = eval(eval_adder(net, input[:input.find('=')+1]))\n",
        "        if target != output:\n",
        "            # print(input, output,)\n",
        "            print(f\"\\r {i}/{len(unseen_data)} {errors/i*100}\",end=\"\")\n",
        "            errors+=1\n",
        "    except:\n",
        "        errors+=1\n",
        "\n",
        "print(f\"Error ={errors/len(unseen_data)*100}%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 606620/606628 6.8260195839240385Error =6.826094410412971%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8LDnmYwzytWd",
        "outputId": "818eab72-06a5-4871-d066-12ae647f1272"
      },
      "source": [
        "eval_adder(net, \"555+234=\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'789.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDmFR0AWHhER"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}