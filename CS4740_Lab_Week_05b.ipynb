{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4740_Lab_Week_05b.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOdLS557D4pVrCBJAfo8UQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvogiatzis/CS4740/blob/main/CS4740_Lab_Week_05b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLVrEeFtaICL"
      },
      "source": [
        "#Exploring the capabilities of Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4MZ5yQgaUSs"
      },
      "source": [
        "In this lab we will carry out a few experiments with Recurrent Neural Networks in order to understand the way these models operate and also to see some interesting applications. RNNs are Deep Learning models that are particularly suitable for sequential data such as time series, text, speech, audio signals etc.\n",
        "\n",
        "We can think of an RNN as a *machine* that is fed a sequence of data-points. After each data-point is entered, the machine performs some calculations based on the information received, and it  modifies its inner state appropriately. It then produces some output before moving to the next data-point in the sequence. \n",
        "\n",
        "We can use RNNs in a multitude of ways:\n",
        "\n",
        "* We can use the last RNN output after a sequence has been read, to make some inference about the type of sequence. E.g. classifying a bit of text into one of a number of categories.\n",
        "* We can use an RNN to encode an input sequence, and pass a code to a second RNN that decodes that into an output sequence. This can form the basis of a sequence-to-sequence mapping, e.g. translation of english to french text.\n",
        "* We can use an RNN as a next-step predictor. E.g. predicting the next day's stock market price from its past history.\n",
        "\n",
        "In this lab we will see a few examples of RNNs: \n",
        "\n",
        "1. A very simple bit-counter\n",
        "2. A text generator\n",
        "3. An *adder* that parses numerical expressions\n",
        "\n",
        "Firstly let's import a few packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsD64X1cnGv5"
      },
      "source": [
        "import re\n",
        "import csv\n",
        "from textblob import Word\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from more_itertools import sliced\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from random import randint\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUT9QqwnrjmM"
      },
      "source": [
        "# A simple running total calculator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoVr2i_OsB_T"
      },
      "source": [
        "This is perhaps the simplest possible RNN we can come up with, that still has a usefull function. The idea is simple: we feed a sequence of numbers and the RNN calculates a running total over those numbers as they come in. \n",
        "\n",
        "First, let's see how the rnn layers work in practice. The main two choices are the GRU and the LSTM, details of which we have seen in lectures. We will be using the GRU throughout this lab but both are drop-in replacements for each other.\n",
        "\n",
        "Let's define a simple GRU layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sd7HbgBskbE"
      },
      "source": [
        "gru = nn.GRU(input_size=2, hidden_size=5)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdJo2k-JxPD2"
      },
      "source": [
        "This module expects to receive sequences of 2-dimensional data points. It crunches them using a hidden layer of size 5, which means that it outputs a sequence of 5-element vectors. Now the actual dimensionality of the input and output is somewhat confusing because of the complexity of batches: it is very important that all NN layers in pytorch are able to handle batched input for standard stochastic gradient descent to work. \n",
        "\n",
        "So the input to RNN layers (by default) is of size \n",
        "\n",
        " `sequence_size` x `batch_size` x `input_size`\n",
        "\n",
        "Why is `batch_size` in the middle I hear you ask? Well it makes sense if we want to iterate through the elements of the sequence. Each element in that sequence is of size `batch_size` x `input_size` and that's exactly what the inner layers of the RNN expect when operating on batches!\n",
        "\n",
        "Having said that, if it is more natural for you to think in terms of batches as the rightmost index, as you would do for a conv or linear layer, `pytorch` allows you to do that by using the `batch_first=True` flag inside RNN constructors. In fact we will be making use of that flag throughout this lab, but bear in mind that `pytorch` is flipping the indices internally.\n",
        "\n",
        "So in our case we would define an input consisting of a batch of 64 sequences, each of which has 100 elements, that are 2-dimensional, we would do it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzCvbFPssEM",
        "outputId": "2dd210b6-fb46-467a-cbfa-3c2b5adcd163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gru = nn.GRU(input_size=2, hidden_size=5)\n",
        "\n",
        "x = torch.randn(100,64,2)\n",
        "y,h = gru(x)\n",
        "\n",
        "y.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 64, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1lIbEuWz3nx"
      },
      "source": [
        "But if we use the `batch_first=True` flag, this becomes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdGFoYqFz85B",
        "outputId": "c0e1fc12-0f12-4149-a84b-1cb7d53f9d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gru = nn.GRU(input_size=2, hidden_size=5, batch_first=True)\n",
        "\n",
        "x = torch.randn(64,100,2)\n",
        "y,h = gru(x)\n",
        "\n",
        "y.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 100, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siTTVNNMnIzy"
      },
      "source": [
        "class CounterNet(nn.Module):\n",
        "    def __init__(self, embed_size=10, hidden_dim=64):\n",
        "        super(CounterNet, self).__init__()\n",
        "        self.rnn = nn.GRU(input_size=1,\n",
        "                        hidden_size=hidden_dim,\n",
        "                        batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x, batch_size=1):\n",
        "        # x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugpeiR3hpdNT",
        "outputId": "e2f60d1f-8056-46ce-c8cf-ac4643ec7895"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size=100\n",
        "num_of_epochs = 5000\n",
        "net = CounterNet().to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss = nn.MSELoss()\n",
        "for e in range(num_of_steps):\n",
        "    x = torch.randint(10, (batch_size,50,1), device=device, dtype=torch.float32)\n",
        "    t = x.cumsum(dim=1,dtype=torch.float32)\n",
        "    y = net(x)\n",
        "    L = loss(y,t)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"\\rEpoch: {e}/{num_of_epochs} \\tL={L}\", end=\"\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4999/5000 \tL=0.01337356399744749"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4_L_WfWm7nU"
      },
      "source": [
        "def evaluate_net(net, input):\n",
        "    x = torch.tensor(input, device=device, dtype=torch.float32).view(1,-1,1)\n",
        "    t = x.cumsum(dim=1,dtype=torch.float32)\n",
        "    y = net(x)\n",
        "    return y"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoS-Habjn-AB",
        "outputId": "671999f0-4553-4f5a-e0ed-64ec50b2b40a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate_net(net,[1,0,0,5])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.9742],\n",
              "         [0.9708],\n",
              "         [1.0471],\n",
              "         [5.9503]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBkYRRwGMPF6"
      },
      "source": [
        "itoc=list('0123456789+=. ')\n",
        "ctoi = {c:i for i,c in enumerate(itoc)}\n",
        "\n",
        "def create_strings(a,b):\n",
        "    c=a+b\n",
        "    a_s=str(a)\n",
        "    b_s=str(b)\n",
        "    c_s=str(c)\n",
        "    input = f'{a_s}+{b_s}={c_s}'\n",
        "    output = f'{c_s}.'\n",
        "    input = f'{a_s}+{b_s}'\n",
        "    output=' ' * len(input)\n",
        "    input += f'={c_s}'\n",
        "    output+= f'{c_s}.'\n",
        "\n",
        "    \n",
        "    return input, output\n",
        "\n",
        "def create_addition_samples(num_samples,ndigits):\n",
        "    x,t,pairs=[],[],[]\n",
        "    for n in range(num_samples):\n",
        "        a = randint(0,10**ndigits-1)\n",
        "        b = randint(0,10**ndigits-1)\n",
        "        input, output = create_strings(a,b)\n",
        "        input = input.ljust(3*ndigits+3, ' ')\n",
        "        output = output.ljust(3*ndigits+3, ' ')\n",
        "        x.append([ctoi[c] for c in input])\n",
        "        t.append([ctoi[c] for c in output])\n",
        "        pairs.append((a,b))\n",
        "    return x,t,pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBxS4ztrzJUX"
      },
      "source": [
        "class AdderNet(nn.Module):\n",
        "    def __init__(self, charset=13, embed_size=15, hidden_dim=1024):\n",
        "        super(AdderNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(charset, embed_size)\n",
        "        self.rnn = nn.GRU(input_size=embed_size,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, charset)\n",
        "        self.h = None\n",
        "\n",
        "    def forward(self, x, batch_size=1, keep_memory=False):\n",
        "        x = self.embedding(x)\n",
        "        if keep_memory:\n",
        "            x, self.h = self.rnn(x,self.h)\n",
        "        else:\n",
        "            x, self.h = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def eval_adder(net, input_str):\n",
        "    itoc=list('0123456789+=. ')\n",
        "    ctoi = {c:i for i,c in enumerate(itoc)}\n",
        "    input = torch.tensor([[ctoi[c] for c in input_str]], device = device)\n",
        "    x = net(input).argmax(dim=2)\n",
        "    x = x[0,-1].view(1,-1)\n",
        "    output = [x.item()]\n",
        "    total_len=0\n",
        "    while x.item() != ctoi['.'] and total_len<10:\n",
        "        x = net(x, keep_memory=True).argmax(dim=2)\n",
        "        output.append(x.item())\n",
        "        total_len+=1\n",
        "    return \"\".join(itoc[i] for i in output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "749bTBqANrty",
        "outputId": "ee2287a4-aa6b-40ec-b714-1ce4ad9d43e6"
      },
      "source": [
        "training_data=set()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size=100\n",
        "num_of_epochs = 5000\n",
        "ndigits=3\n",
        "net = AdderNet(charset = len(itoc)).to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "for e in range(num_of_epochs):\n",
        "    x,t,pairs = create_addition_samples(batch_size,ndigits=ndigits)\n",
        "    training_data =training_data.union(set(pairs))\n",
        "    x = torch.tensor(x,device=device)\n",
        "    t = torch.tensor(t,device=device)\n",
        "    y = net(x)\n",
        "    L = loss(y.view(-1,y.shape[-1]),t.view(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"\\rEpoch: {e}/{num_of_epochs} \\tL={L}\", end=\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4999/5000 \tL=0.018413158133625984"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJaY7vaEm3on"
      },
      "source": [
        "all_pairs = set((a,b) for a in range(1000) for b in range(1000))\n",
        "unseen_data=list(all_pairs.difference(training_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wimaOiEo1tg",
        "outputId": "a2b1d63b-1a43-4e00-a192-bfea39df6af4"
      },
      "source": [
        "errors=0\n",
        "for i,(a,b) in enumerate(unseen_data):\n",
        "    input, output = create_strings(a,b)\n",
        "    # net_output = eval(eval_adder(net, input[:input.find('=')+1]))\n",
        "    try:\n",
        "        target = eval(input[:input.find('=')])\n",
        "        output = eval(eval_adder(net, input[:input.find('=')+1]))\n",
        "        if target != output:\n",
        "            # print(input, output,)\n",
        "            print(f\"\\r {i}/{len(unseen_data)} {errors/i*100}\",end=\"\")\n",
        "            errors+=1\n",
        "    except:\n",
        "        errors+=1\n",
        "\n",
        "print(f\"Error ={errors/len(unseen_data)*100}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 606620/606628 6.8260195839240385Error =6.826094410412971%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8LDnmYwzytWd",
        "outputId": "818eab72-06a5-4871-d066-12ae647f1272"
      },
      "source": [
        "eval_adder(net, \"555+234=\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'789.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDmFR0AWHhER"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}