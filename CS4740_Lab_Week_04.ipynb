{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4740_Lab_Week_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUDY1dzO4nJQ4PMHTbTP1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b82b883c4e674ad397a95fd3502dae9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95e24a21b3494446bef471205a48cbe6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4140ad81342492683d6458529a3e99a",
              "IPY_MODEL_c729f81285604d5bae6bbfd34bffbadb"
            ]
          }
        },
        "95e24a21b3494446bef471205a48cbe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4140ad81342492683d6458529a3e99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c30fe2bf70ae4111a234a94fb781419e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0727936ad4fe42bcbe42d69cbf100cb9"
          }
        },
        "c729f81285604d5bae6bbfd34bffbadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef4631afe41f46769fa6ec7f64392383",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 52069587.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33c7fd32cb054182937bd7716e14038d"
          }
        },
        "c30fe2bf70ae4111a234a94fb781419e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0727936ad4fe42bcbe42d69cbf100cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef4631afe41f46769fa6ec7f64392383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33c7fd32cb054182937bd7716e14038d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvogiatzis/CS4740/blob/main/CS4740_Lab_Week_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtZOri9fuqF"
      },
      "source": [
        "#CS4740 Labs\n",
        "##Week 4 - Convolutional Neural Networks\n",
        "\n",
        "In this lab we will extend the classifier we have seen previously, to CIFAR10, a more challenging dataset of real (although very low-res) images. The dataset is split into ten classes (see below) and there is significant variability within each class.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1bn4UqHwT0v7Twk01KS9d_jVlOQpeMaNc'/>\n",
        "<figcaption>CIFAR10 images</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "To classify this dataset correctly we will need to upgrade our network to use convolutional layers. And because convolutions are very computationally demanding, we will see how to offload some of those computations to the GPU, dramatically reducing training times. \n",
        "\n",
        "## Section 1 - loading and exploring the dataset\n",
        "\n",
        "First, let us load up the CIFAR10 dataset, for both training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SudY_3wf3Qn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "b82b883c4e674ad397a95fd3502dae9c",
            "95e24a21b3494446bef471205a48cbe6",
            "c4140ad81342492683d6458529a3e99a",
            "c729f81285604d5bae6bbfd34bffbadb",
            "c30fe2bf70ae4111a234a94fb781419e",
            "0727936ad4fe42bcbe42d69cbf100cb9",
            "ef4631afe41f46769fa6ec7f64392383",
            "33c7fd32cb054182937bd7716e14038d"
          ]
        },
        "outputId": "edaaac02-235a-4726-db93-a6719bd34727"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10('.', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10('.', train=False, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b82b883c4e674ad397a95fd3502dae9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhzjyj-0WMGF"
      },
      "source": [
        "Let's examine one of the training datapoints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgkv-SbiWghN",
        "outputId": "8b646ff1-1b8d-4ee3-d2a2-bbd55beca31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "img, target = train_dataset[30]\n",
        "print(img.shape)\n",
        "plt.imshow(img.permute([1,2,0]))\n",
        "print(train_dataset.classes[target])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFhLhDj-X1dH"
      },
      "source": [
        "The images are 32 by 32 and contain 3 color channels which is what we would expect for color images. This is very low res, however if a human is able to correctly classify these images, we should be able to program a neural network. We will be using a convolutional neural network architecture for this task, but first, let us understand how pytorch performs convolutions. \n",
        "\n",
        "We define a convolutional layer with the Conv2d class. The constructor takes the input and output number of channels as well as the size of the convolution kernel. Consider the following convolution layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YOf3hAhTiPG"
      },
      "source": [
        "conv = nn.Conv2d(3, 16, 5)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CNxyrnehzJA"
      },
      "source": [
        "This layer is applied on tensors with 3 channels, and outputs a tensor with 16 channels. The size of the kernel is 5x5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYz2fT1kTqW6",
        "outputId": "bca89c18-7b1c-44c1-cd12-d5cb66688d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "img, target = train_dataset[30]\n",
        "plt.imshow(img.permute([1,2,0]))\n",
        "print(target)\n",
        "\n",
        "img = img[None,:,:,:]\n",
        "print(img.shape)\n",
        "out = conv(img)\n",
        "print(out.shape)\n",
        "print(train_dataset.classes[target])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([1, 3, 32, 32])\n",
            "torch.Size([1, 16, 28, 28])\n",
            "airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHGDn28KiBIg"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        self.conv2 = nn.Conv2d(16, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 256, 5)\n",
        "        self.conv4 = nn.Conv2d(256, 128, 1)\n",
        "        self.conv5 = nn.Conv2d(128, 10, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.conv5(x)\n",
        "        return x.view(-1,10)\n",
        "\n",
        "convnet = ConvNet()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGGqgx4LS-6U"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKlwm-h8nRJn"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=1000, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_T4UAxY7PVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6379fc38-8dc2-4875-f750-c0eebb470d6a"
      },
      "source": [
        "x,t = next(iter(train_loader))\n",
        "# x,t=x.cuda(),t.cuda()\n",
        "convnet(x).shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH6Q-JmtSSv_",
        "outputId": "5b00ac54-3d73-47c3-a154-72b6ab278a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "convnet."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LydAUpLgit6B"
      },
      "source": [
        "def train(net,dataloader, optimizer,loss_fun):\n",
        "  net.train()\n",
        "  for x, t in dataloader:\n",
        "    # x = x.cuda()\n",
        "    # t = t.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    L = loss_fun(net(x), t)\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def test(net,dataloader,loss_fun):\n",
        "  net.eval()\n",
        "  total_L = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for x, t in dataloader:\n",
        "    #   x = x.cuda()\n",
        "    #   t = t.cuda()\n",
        "      out = net(x)\n",
        "      total_L += loss_fun(out, t)\n",
        "      _,pred = out.max(dim=1)     # this counts how many we got right\n",
        "      correct += (pred==t).sum() \n",
        "  total_L /= len(dataloader.dataset)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    total_L, correct, len(dataloader.dataset),\n",
        "    100. * correct / len(dataloader.dataset)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA4ptMJHivDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "72075423-0da1-4ab8-ff42-8038b371ffbb"
      },
      "source": [
        "optim_SGD = optim.SGD(convnet.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "for e in range(100):\n",
        "  print(f\"Epoch: {e+1}/10. Training ...\")\n",
        "  train(convnet, train_loader, optim_SGD, nn.CrossEntropyLoss())\n",
        "  print(\"Testing ...\")\n",
        "  test(convnet, test_loader,  nn.CrossEntropyLoss(reduction='sum'))  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10. Training ...\n",
            "Testing ...\n",
            "\n",
            "Test set: Avg. loss: 2.0482, Accuracy: 2544/10000 (25%)\n",
            "\n",
            "Epoch: 2/10. Training ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9dabcc685258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {e+1}/10. Training ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_SGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-688f9f984984>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataloader, optimizer, loss_fun)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# x = x.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# t = t.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mgetbands\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \"\"\"\n\u001b[0;32m-> 1192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImageMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WyBP4L4-fuV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}