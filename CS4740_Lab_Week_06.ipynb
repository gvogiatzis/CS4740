{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4740_Lab_Week_06.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmAD+oMbLTJyjyZh8Ml86l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvogiatzis/CS4740/blob/main/CS4740_Lab_Week_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmNmOeK20Eat"
      },
      "source": [
        "# [CS4740 Labs] Week 6: Deep Generative Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMog9XKI3kmJ"
      },
      "source": [
        "##Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mClXvBar1zjf"
      },
      "source": [
        "One of the big successes of Deep Learning that sparked significant interest in the last few years is Deep Generative Models. These are deep neural architectures whose main goal is *analysis-by-synthesis*. In other words, they represent an attempt to analyse a complex dataset by synthesizing new datapoints that preserve the statistical properties of the original data. In achieving this, the deep generative models are able to extract meaningful information about the statistical distribution that gave rise to the original dataset, thereby providing us with some sort of *high-level understanding*. \n",
        "\n",
        "These Deep Generative architectures have been used to generate realistic data from a variety of sources, including among others, celebrity face images and artistic paintings!\n",
        "\n",
        "In this lab we will explore some of the properties of Deep Generative Models by running several experiments using popular generative architectures. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "258RXXL2Xqgi"
      },
      "source": [
        "##A very simple VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvZuCnvYXtsw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ZShz3dX1Wu"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "def spiral(n_points, noise=1.5):\n",
        "    n = np.sqrt(np.random.rand(n_points,1)) * 780 * (2*np.pi)/360\n",
        "    dx = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
        "    dy = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
        "    return np.hstack((dx,dy))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w63j04_IXw4P"
      },
      "source": [
        "class MLPNet(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden=[3], output_size=2):\n",
        "        super(MLPNet, self).__init__()\n",
        "        s0=input_size\n",
        "        self.layers = nn.ModuleList()\n",
        "        for h in hidden:\n",
        "            # self.layers.append(nn.Sequential(nn.Linear(s0,h),nn.ReLU()))\n",
        "            self.layers.append(nn.Sequential(nn.Linear(s0,h),nn.LeakyReLU()))\n",
        "            s0=h\n",
        "        self.classifier= nn.Linear(s0,output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for f in self.layers:\n",
        "            x = f(x)\n",
        "        return self.classifier(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRD1Gq6_X5jJ"
      },
      "source": [
        "N = 1000\n",
        "\n",
        "# X, _ = make_blobs(n_samples=N, centers=4, cluster_std=0.60, random_state=0)\n",
        "X = spiral(n_points=N)\n",
        "# plt.plot(X[:,0],X[:,1],'rx')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlx8HtDPX7pi"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.tensor(X,dtype=torch.float, device=device)\n",
        "num_of_epochs = 10000\n",
        "z_dim = 1\n",
        "\n",
        "enc = MLPNet(input_size=2, hidden=[64,256,512,128], output_size=z_dim).to(device)\n",
        "dec = MLPNet(input_size=z_dim, hidden=[64,256,512,128], output_size=2).to(device)\n",
        "# enc = MLPNet(input_size=2, hidden=[128,256,128], output_size=z_dim).to(device)\n",
        "# dec = MLPNet(input_size=z_dim, hidden=[128,256,128], output_size=2).to(device)\n",
        "\n",
        "optimizer = optim.Adam(chain(enc.parameters(),dec.parameters()), lr=0.001)\n",
        "\n",
        "loss = nn.MSELoss(reduction='mean')\n",
        "\n",
        "for e in range(num_of_epochs):\n",
        "    z = enc(x)\n",
        "    z += 1e-2*torch.randn_like(z, device=device)\n",
        "    x_ = dec(z)\n",
        "    L = loss(x, x_) + 1e-4*z.square().sum()\n",
        "    L = loss(x, x_)\n",
        "    # L=loss(x,dec(enc(x)))\n",
        "    optimizer.zero_grad()\n",
        "    L.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e%1000 ==0:\n",
        "        # z_ = torch.linspace(min(z).item(),max(z).item(),100,device=device).view(-1,1)\n",
        "        # x_ = dec(z_)\n",
        "        # x_ = x_.cpu().detach().numpy()\n",
        "        # plt.figure()\n",
        "        # plt.plot(X[:,0],X[:,1],'x')\n",
        "        # plt.plot(x_[:,0],x_[:,1],'-')\n",
        "        # plt.title(f\"{L.item()}\")\n",
        "        # plt.show()\n",
        "        x_ = dec(enc(x))\n",
        "        x_ = x_.cpu().detach().numpy()\n",
        "        plt.figure()\n",
        "        plt.plot(X[:,0],X[:,1],'x')\n",
        "        plt.plot(x_[:,0],x_[:,1],'+')\n",
        "        plt.title(f\"{L.item()}\")\n",
        "        plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCy_4nr7FBJS",
        "outputId": "abef21c1-e695-44f6-ec87-49e1f457a3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "z=enc(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fe41632de709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'enc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVj6s7gF3nhV"
      },
      "source": [
        "## A very simple GAN\n",
        "\n",
        "Before we can "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh8FGW96umgB"
      },
      "source": [
        "N = 1000\n",
        "\n",
        "# X, _ = make_blobs(n_samples=N, centers=4, cluster_std=0.60, random_state=0)\n",
        "X = spiral(n_points=N)\n",
        "# plt.plot(X[:,0],X[:,1],'rx')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddj1udPyBXAa"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.tensor(X,dtype=torch.float, device=device)\n",
        "num_of_epochs = 50000\n",
        "z_dim = 2\n",
        "\n",
        "disc = MLPNet(input_size=2, hidden=[128,256,128], output_size=1).to(device)\n",
        "gen = MLPNet(input_size=z_dim, hidden=[128,256,128], output_size=2).to(device)\n",
        "\n",
        "optim_d = optim.Adam(disc.parameters(), lr=0.001)\n",
        "optim_g = optim.Adam(gen.parameters(), lr=0.001)\n",
        "\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for e in range(num_of_epochs):\n",
        "    z = torch.randn(N,z_dim, device=device)\n",
        "\n",
        "    L_dis = (loss(disc(gen(z)),torch.zeros(N,1,device=device)) +\n",
        "            loss(disc(x), torch.ones(N,1,device=device)))\n",
        "    optim_d.zero_grad()\n",
        "    L_dis.backward()\n",
        "    optim_d.step()\n",
        "\n",
        "    L_gen = loss(disc(gen(z)),torch.ones(N,1,device=device))\n",
        "    optim_g.zero_grad()\n",
        "    L_gen.backward()\n",
        "    optim_g.step()\n",
        "\n",
        "    if e%1000 ==0:\n",
        "        x_gen = gen(z).cpu().detach().numpy()\n",
        "        plt.figure()\n",
        "        plt.plot(X[:,0],X[:,1],'x')\n",
        "        plt.plot(x_gen[:,0],x_gen[:,1],'+')\n",
        "        plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vp4VRKSz8aM"
      },
      "source": [
        "Try with one-dimensional $z$."
      ]
    }
  ]
}